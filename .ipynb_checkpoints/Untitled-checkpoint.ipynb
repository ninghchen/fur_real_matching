{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec6537e-70ec-4ced-a6cd-567f4df99c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"Lead and conduct complex data analyses and developing analytical solutions for a broad range of ad hoc requests from auditors, investigators, and other OIG staff. Collect, clean, transform, raw data; utilize data science and statistical methods (e.g. sampling and modeling) and tools (e.g. Python, R, SQL, PowerBI) to combine data sets and develop meaningful insights and recommendations for customers.\n",
    "Develop and manage data pipelines from various platforms (such as SAP and working with APIs either in on-premise settings or with cloud architecture), data models, and architecture for continuous monitoring and proactive monitoring projects, data warehouses, and dashboards. Thoroughly document ETL procedures for continuity of operations. Manage data warehouse to include user permissions, change management, troubleshooting, and coordinating with Information Technology support staff.\n",
    "Provide expert technical advice on methodologies used, interpreting data, results of analyses, and data science best practices. Develop written products, visual aids, and oral presentations to OIG executives and employees that clearly communicate findings and recommendations on complex subjects.\n",
    "Collaborate with cross-functional teams across the OIG to identify opportunities for leveraging data to support audit and investigative work, solve complex business problems, and drive innovation. Support and train others in data science principles, methods, and tools.\n",
    "Build and maintain relationships with outside data experts and counterparts in the DOI, other OIGs, and other organizations. Participate in data initiatives initiated by the Council of Inspectors General for Integrity and Efficiency (CIGIE). Maintain awareness of emerging data science technologies and issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4892fe82-a42d-4ca3-a1d8-11ae46d6a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\"EDUCATION\n",
    "December 2015, Ph.D., Computer Science, Old Dominion University, Norfolk, VA, USA. December 2009, M.S., Physical Chemistry, New Mexico State University, Las Cruces, NM, USA. July 2001, B.S., Chemistry, Lanzhou University, Lanzhou, Gansu, P. R. China\n",
    "   EMPLOYMENT\n",
    "Langley AFB, Hampton VA\n",
    "Computer Engineer\n",
    "York County School Division, Yorktown, VA\n",
    "Volunteer Gifted Education Advisory Committee\n",
    "Virginia Peninsula Chinese School, Newport News, VA\n",
    "Volunteer Peninsula Chinese School Committee\n",
    "Valdosta State University, Valdosta GA\n",
    "Assistant Professor in Department of Computer Science\n",
    "Graduate Faculty\n",
    "Elizabeth City State University, Elizabeth City NC\n",
    "Assistant Professor in Department of Mathematics and Computer Science Full Graduate Faculty\n",
    "Army Research Lab, Adelphi MD\n",
    "TMCF Summer Research Fellow\n",
    "Jan, 2021 – present Aug, 2021 – Present\n",
    "Aug, 2021 – Present\n",
    "Aug, 2019 – Dec, 2020 Nov, 2020 – Dec, 2020\n",
    "Aug, 2016 – July, 2019 Feb, 2018 – July, 2019\n",
    "June, 2017 – Aug, 2017\n",
    " NASA Langley Research Center, Hampton VA | Science Applications International Corporation, Inc.\n",
    "Senior Software Developer Nov, 2015 – July, 2016\n",
    "NASA Langley Research Center, Hampton VA | Stinger Ghaffarian Technologies, Inc.\n",
    "Senior Software Developer Feb, 2014 – Oct, 2015\n",
    "RESEARCH INTERESTS\n",
    "Computational biology, Machine learning, High performance computing, Image processing, Algorithm, Monte Carlo Simulation\n",
    " TEACHING EXPERIENCE\n",
    "Valdosta State University, Valdosta GA\n",
    "Assistant Professor\n",
    "CS 1000 Intro to Microcomputer/Applications (Fall 2019)\n",
    "CS 1301 Principles of Programming I (Fall 2019, Spring 2020, Fall 2020) CS 2620 Discrete Structures (Fall 2019, Fall 2020)\n",
    "CS 3335 The C Programming Language (Fall 2020)\n",
    "CS 4900 Senior Seminar (Spring 2020)\n",
    "Elizabeth City State University, Elizabeth City NC\n",
    "Assistant Professor\n",
    "BMIS 485 Business Intelligence & Data Analytics, online (Spring 2019) CSC115 Programming I (Fall 2016, Spring 2017)\n",
    "Aug, 2019 – Dec, 2020\n",
    "Aug, 2016 – July, 2019\n",
    " \n",
    "Lin Chen | Web: https://lin-chen-langley.github.io/\n",
    "CSC215 Programming II (Fall 2016)\n",
    "CSC218 Data Structure (Spring 2019)\n",
    "CSC230 Java Programming (Spring 2017, Fall 2017)\n",
    "CSC315 Programming Languages (Fall 2018)\n",
    "CSC318 Algorithm (Fall 2017, Fall 2018)\n",
    "CSC325 Database and Intelligence Sys (Spring 2017, Spring 2018, Spring 2019)\n",
    "CSC401 Data Mining and Machine Learning (Spring 2018, Spring 2019)\n",
    "CSC410 Net-Centric Computing (Fall 2016, Fall 2017, Fall 2018)\n",
    "CSC412 Software Methodology and Engineer (Fall 2016, Spring 2017, Fall 2017, Fall 2018) CSC413 System Analysis and Design (Spring 2018)\n",
    "CSC414 Python Programming and Visualization (Spring 2018, Fall 2018)\n",
    "CSC420 Operating System (Spring 2019)\n",
    "  University of the People, Pasadena CA\n",
    "Online Volunteer Instructor\n",
    "Taught CS 1103 Java Programming II\n",
    "SKILLS\n",
    "Machine Learning:\n",
    "Scikit-learn, Tensorflow 2, MATLAB machine learning toolbox\n",
    "High Performance Computing:\n",
    "MPI, CUDA, OpenACC, Pthreads, OpenMP, Hadoop\n",
    "Image Processing:\n",
    "OpenCV, ImageJ, Matlab image processing toolbox, Chimera\n",
    "Programming:\n",
    "Nov, 2015 – April, 2016\n",
    " C/C++, Pyhton, Java, bash shell, MATLAB, Oracle SQL, SQLite, MySQL, Html, CSS, PHP, Javascript, React/Redux, XML, AJAX, JQuery, JSON, R, Fortran\n",
    "Tools:\n",
    "Git, Docker, Kubernetes, Latex, GIMP, Origin\n",
    "Teaching:\n",
    "Blockboard; BlazeView; Moodle; MyLab\n",
    "RESEARCH AND INDUSTRY EXPERIENCE\n",
    "Design of a Chimera tool for Protein Anomaly Detection, Faculty Research\n",
    "Jan, 2019 – Dec, 2020\n",
    " Designed an approach to detect the anomalous protein structures solved from Cryo-EM method.\n",
    "Module and Library: Chimera, Tkinter, biopython\n",
    "Coding languages: Python\n",
    "Protein Structure Anomaly Detection, Faculty Research Oct, 2016 – Dec, 2020 Designed an approach to detect the anomalous protein structures solved from Cryo-EM method.\n",
    "Techniques: statistics\n",
    "Module and Library: biopython\n",
    "Coding languages: Python\n",
    "Optimized Machine Learning for Human Agent Teaming, ARL Project\n",
    "Designed and conducted an approach to identify image sense by deep learning methods.\n",
    "Summer, 2017\n",
    "\n",
    "Lin Chen | Web: https://lin-chen-langley.github.io/\n",
    "  Techniques: image processing, deep learning\n",
    "Modules and Libraries: scikit-image, tensorflow, MATLAB image processing toolbox, MATLAB computer vision toolbox Coding language: MATLAB, Python\n",
    "Web Crawling to Matching miRNA ID to Expression, NIH-MARC Project Spring, 2017 Conducted a web crawling to match miRNA ID and its expression by searching mirbase.org and targetscan.org. Modules and Libraries: urllib2, beautifulsoup\n",
    "Coding language: Python\n",
    "NDE, NASA Langley Research Project June, 2014 – June, 2016 Designed an algorithm and delivered a software for delamination detection from CT image.\n",
    "Modules and Libraries: scikit-image, tensorflow, MATLAB image processing toolbox, MATLAB computer vision toolbox Techniques: image processing, machine learning, high performance computing\n",
    "Modules and Libraries: MATLAB image processing toolbox, MATLAB machine learning toolbox, MATLAB mex, C++11 STL, C++ Eigen\n",
    "Coding languages: MATLAB, Python, C++\n",
    "WCA, NASA Langley Project\n",
    "Supported IBM Watson Content Analytics system for Information Management Branch.\n",
    "Modules and Libraries: xml, urllib2, beautifulsoup\n",
    "Coding languages: Python, Java, WordPress\n",
    "HPC, NASA Langley Research Project\n",
    "Conducted a prototype using both Phi and GPU on NASA cluster.\n",
    "Techniques: high performance computing\n",
    "Modules and Libraries: MPI MVAPICH2, OpenMP, C++ Boost, CUDA, OpenACC, Qt\n",
    "Coding languages: C++\n",
    "ADT, NASA Langley Project\n",
    "Supported building a website hosting machine learning models for research and training purpose.\n",
    "Coding languages: Python, PHP, HTML, CSS\n",
    "Protein Energy Function Design, Ph. D. Research\n",
    "Designed and generated energy function for protein structure prediction.\n",
    "Techniques: Boltzmann theory, thermodynamics, high performance computing\n",
    "Coding languages: C++\n",
    "Algorithm design, Ph. D. Research\n",
    "Designed a top-K algorithm for the native topology searching in protein prediction\n",
    "Techniques: graph theory, image processing\n",
    "Coding languages: C++\n",
    "CNT Simulation, Master Research\n",
    "Simulated the purification of small chemicals in aqueous solution by carbon nanotube.\n",
    "Techniques: Monte Carlo simulation, thermodynamics\n",
    "Coding languages: C++, Fortran\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f8587b-0d60-45aa-a0ec-2b9a06305e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "similarity_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b59f2f-1908-4792-9528-73c47a1986b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a69803-a749-44b7-baeb-252c80a9c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "summarizer = Summarizer(custom_model=model, custom_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d92dc32-97f2-4b6f-850e-9835632c5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sentences = summarizer.sentence_handler(job_description)\n",
    "resume_sentences = summarizer.sentence_handler(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4621421-7b71-4b0f-9683-4af0cca84411",
   "metadata": {},
   "outputs": [],
   "source": [
    "js_embeddings = similarity_model.encode(job_sentences)\n",
    "rs_embeddings = similarity_model.encode(resume_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75d486bd-2fde-41d5-8979-f161dddd97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "rows = len(js_embeddings)\n",
    "columns = len(rs_embeddings)\n",
    "\n",
    "similarities = np.zeros((rows, columns))\n",
    "\n",
    "for js_index, js in enumerate(js_embeddings):\n",
    "    for rs_index, rs in enumerate(rs_embeddings):\n",
    "        similarity = cosine_similarity(js.reshape(1, -1), rs.reshape(1, -1))\n",
    "        similarities[js_index][rs_index] = similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a14b7ec-f343-4735-be7c-3e247a61a3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34754923, -0.07677425,  0.11638742,  0.09456465,  0.05841025,\n",
       "         0.07418079,  0.16528952,  0.22874512,  0.20589438,  0.21872318,\n",
       "         0.11793138,  0.18635774,  0.08403713,  0.20843512],\n",
       "       [ 0.39312524, -0.14633031,  0.12432238,  0.19759396,  0.09787279,\n",
       "         0.11558947,  0.32897317,  0.33708981,  0.3358053 ,  0.26544774,\n",
       "         0.13010293,  0.22849323,  0.13422373,  0.27472621],\n",
       "       [ 0.36596742, -0.11485434,  0.09427446,  0.14109354,  0.10990135,\n",
       "         0.07829119,  0.30961433,  0.4043383 ,  0.3190411 ,  0.26575392,\n",
       "         0.05197846,  0.21796492,  0.09580716,  0.26503375],\n",
       "       [ 0.20462587, -0.10795815, -0.00611361,  0.08114219,  0.03543446,\n",
       "         0.13206173,  0.10227011,  0.09955981,  0.03463849,  0.11083597,\n",
       "         0.00771203,  0.06152963, -0.01105343,  0.10001101],\n",
       "       [ 0.25330624, -0.12645137,  0.03046471,  0.07041278, -0.00853167,\n",
       "         0.05642807,  0.14845505,  0.1761359 ,  0.16897362,  0.10850144,\n",
       "         0.01998976,  0.07937969,  0.02381999,  0.1019318 ],\n",
       "       [ 0.36403185, -0.10138078,  0.08781658,  0.13152018,  0.11796336,\n",
       "         0.11799801,  0.25217107,  0.25150895,  0.28707528,  0.25746667,\n",
       "         0.18408594,  0.22568217,  0.14422092,  0.26419985],\n",
       "       [ 0.30540264, -0.11202605,  0.00662543,  0.10984981,  0.12493062,\n",
       "         0.08677794,  0.14008734,  0.16513062,  0.14884287,  0.17600594,\n",
       "         0.07116887,  0.09955301,  0.01118981,  0.10568324],\n",
       "       [ 0.34618753, -0.11679579,  0.06627952,  0.20324832,  0.14119813,\n",
       "         0.0727122 ,  0.19933784,  0.22925082,  0.21474086,  0.11970145,\n",
       "         0.09191599,  0.13212118,  0.07017118,  0.1467931 ],\n",
       "       [ 0.39370555, -0.05739868,  0.08664967,  0.20543294,  0.11287377,\n",
       "         0.11786078,  0.28134298,  0.28459394,  0.32848722,  0.25570777,\n",
       "         0.15639466,  0.23355478,  0.13501681,  0.23801202],\n",
       "       [ 0.29110676, -0.06064878,  0.08556914,  0.09208822,  0.14114684,\n",
       "         0.12051374,  0.15673059,  0.21345556,  0.1807667 ,  0.14120394,\n",
       "         0.0994171 ,  0.09069473,  0.08533084,  0.13297054],\n",
       "       [ 0.23728621, -0.13164952,  0.0371986 ,  0.07369973,  0.11610827,\n",
       "         0.0808061 ,  0.1108266 ,  0.19442225,  0.16343063,  0.09531961,\n",
       "         0.01275476,  0.05693947, -0.00528415,  0.09543087],\n",
       "       [ 0.37664932, -0.07420681,  0.11889192,  0.17628604,  0.1553138 ,\n",
       "         0.10191059,  0.2420311 ,  0.29076296,  0.32649672,  0.1985887 ,\n",
       "         0.12249253,  0.18378291,  0.16207731,  0.16921356]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9485f643-982e-4540-a980-90510c2b452d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for row in range(rows):\n",
    "    col = np.argmax(similarities[row])\n",
    "    print(job_sentences[row])\n",
    "    print(resume_sentences[col])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
